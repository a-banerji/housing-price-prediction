{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "573c60db-1d2b-42fc-bfec-6f43517fec4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This file loads the data from the data folder and runs multiple\n",
    "models and hypertunings and finally stores the final model in the\n",
    "pickles folder and model scores in the outputs folder.\n",
    "\"\"\"\n",
    "\n",
    "import argparse\n",
    "import logging\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import pathlib\n",
    "import optuna\n",
    "import pickle\n",
    "import sys\n",
    "from scipy.stats import randint\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.model_selection import (\n",
    "    GridSearchCV,\n",
    "    RandomizedSearchCV,\n",
    "    StratifiedShuffleSplit,\n",
    "    train_test_split,\n",
    ")\n",
    "from sklearn.tree import DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "74319587-b645-4c0a-ac23-e2ed12ec30c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.5"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([1,3,6,8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ffea5b61-595c-4478-8355-9c8b79abf29f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--output_path OUTPUT_PATH]\n",
      "                             [--log-level {DEBUG,INFO,WARNING,ERROR,CRITICAL}]\n",
      "                             [--log-path LOG_PATH]\n",
      "                             [--no-console-log NO_CONSOLE_LOG]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f /root/.local/share/jupyter/runtime/kernel-8437230c-87a4-424c-823a-5d198d2b2c58.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/check-dev/lib/python3.9/site-packages/IPython/core/interactiveshell.py:3405: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "def fit_direct_data(housing, model_output_path='',\n",
    "                    base_path=\"\"):#pathlib.Path(__file__).parent.parent.resolve()):\n",
    "\n",
    "    train_set, test_set = train_test_split(housing, test_size=0.2,\n",
    "                                           random_state=42)\n",
    "\n",
    "    housing[\"income_cat\"] = pd.cut(housing[\"median_income\"],\n",
    "                                   bins=[0., 1.5, 3.0, 4.5, 6., np.inf],\n",
    "                                   labels=[1, 2, 3, 4, 5])\n",
    "\n",
    "    split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "    for train_index, test_index in split.split(housing, housing[\"income_cat\"]):\n",
    "        strat_train_set = housing.loc[train_index]\n",
    "        strat_test_set = housing.loc[test_index]\n",
    "\n",
    "    def income_cat_proportions(data):\n",
    "        return data[\"income_cat\"].value_counts() / len(data)\n",
    "\n",
    "    train_set, test_set = train_test_split(housing, test_size=0.2,\n",
    "                                           random_state=42)\n",
    "\n",
    "    compare_props = pd.DataFrame({\n",
    "        \"Overall\": income_cat_proportions(housing),\n",
    "        \"Stratified\": income_cat_proportions(strat_test_set),\n",
    "        \"Random\": income_cat_proportions(test_set),\n",
    "    }).sort_index()\n",
    "    compare_props[\"Rand. %error\"] = 100 * compare_props[\"Random\"] \\\n",
    "        / compare_props[\"Overall\"] - 100\n",
    "    compare_props[\"Strat. %error\"] = 100 * compare_props[\"Stratified\"] \\\n",
    "        / compare_props[\"Overall\"] - 100\n",
    "\n",
    "    for set_ in (strat_train_set, strat_test_set):\n",
    "        set_.drop(\"income_cat\", axis=1, inplace=True)\n",
    "\n",
    "    housing = strat_train_set.copy()\n",
    "    housing.plot(kind=\"scatter\", x=\"longitude\", y=\"latitude\")\n",
    "    housing.plot(kind=\"scatter\", x=\"longitude\", y=\"latitude\", alpha=0.1)\n",
    "\n",
    "    corr_matrix = housing.corr()\n",
    "    corr_matrix[\"median_house_value\"].sort_values(ascending=False)\n",
    "    housing[\"rooms_per_household\"] = housing[\"total_rooms\"]\\\n",
    "        / housing[\"households\"]\n",
    "    housing[\"bedrooms_per_room\"] = housing[\"total_bedrooms\"]\\\n",
    "        / housing[\"total_rooms\"]\n",
    "    housing[\"population_per_household\"] = housing[\"population\"]\\\n",
    "        / housing[\"households\"]\n",
    "\n",
    "    housing = strat_train_set.drop(\n",
    "        \"median_house_value\", axis=1)  # drop labels for training set\n",
    "    housing_labels = strat_train_set[\"median_house_value\"].copy()\n",
    "\n",
    "    imputer = SimpleImputer(strategy=\"median\")\n",
    "\n",
    "    housing_num = housing.drop('ocean_proximity', axis=1)\n",
    "\n",
    "    imputer.fit(housing_num)\n",
    "    X = imputer.transform(housing_num)\n",
    "\n",
    "    housing_tr = pd.DataFrame(X, columns=housing_num.columns,\n",
    "                              index=housing.index)\n",
    "    housing_tr[\"rooms_per_household\"] = housing_tr[\"total_rooms\"]\\\n",
    "        / housing_tr[\"households\"]\n",
    "    housing_tr[\"bedrooms_per_room\"] = housing_tr[\"total_bedrooms\"]\\\n",
    "        / housing_tr[\"total_rooms\"]\n",
    "    housing_tr[\"population_per_household\"] = housing_tr[\"population\"]\\\n",
    "        / housing_tr[\"households\"]\n",
    "\n",
    "    housing_cat = housing[['ocean_proximity']]\n",
    "    housing_prepared = housing_tr.join(\n",
    "                        pd.get_dummies(housing_cat, drop_first=True))\n",
    "    \n",
    "    global best_parms\n",
    "    \n",
    "    def objective(trial,housing_prepared, housing_labels):\n",
    "        n_estimators=trial.suggest_int(\"n_estimators\", [3, 10, 30])\n",
    "        max_features=trial.suggest_int(\"max_features\", [2, 4, 6, 8])\n",
    "        \n",
    "        param_grid = [\n",
    "            # try 12 (3×4) combinations of hyperparameters\n",
    "            {'n_estimators': n_estimators, 'max_features': max_features},\n",
    "            # then try 6 (2×3) combinations with bootstrap set as False\n",
    "            {'bootstrap': [False], 'n_estimators': n_estimators,\n",
    "             'max_features': max_features},\n",
    "        ]\n",
    "\n",
    "        forest_reg = RandomForestRegressor(random_state=42)\n",
    "        # train across 5 folds, that's a total of (12+6)*5=90 rounds of training\n",
    "        grid_search = GridSearchCV(forest_reg, param_grid, cv=5,\n",
    "                                   scoring='neg_mean_squared_error',\n",
    "                                   return_train_score=True)\n",
    "        grid_search.fit(housing_prepared, housing_labels)\n",
    "\n",
    "        best_parms = grid_search.best_params_\n",
    "        cvres = grid_search.cv_results_\n",
    "        ss=[]\n",
    "        for mean_score, params in zip(cvres[\"mean_test_score\"], cvres[\"params\"]):\n",
    "            print(np.sqrt(-mean_score), params)\n",
    "            ss.append(np.sqrt(-mean_score))\n",
    "\n",
    "        return ss.mean()\n",
    "    \n",
    "    study = optuna.create_study(directions='maximize')\n",
    "    study.optimize(objective, n_trial=50)\n",
    "\n",
    "    feature_importances = grid_search.best_estimator_.feature_importances_\n",
    "    sorted(zip(feature_importances, housing_prepared.columns), reverse=True)\n",
    "\n",
    "    final_model = grid_search.best_estimator_\n",
    "\n",
    "    if model_output_path == '':\n",
    "        # checks for user arguments, is empty stores default.\n",
    "        filename = os.path.join(base_path, 'pickles/finalized_model.sav')\n",
    "    else:\n",
    "        filename = os.path.join(model_output_path, 'finalized_model.sav')\n",
    "\n",
    "    pickle.dump(final_model, open(filename, 'wb'))\n",
    "\n",
    "    X_test = strat_test_set.drop(\"median_house_value\", axis=1)\n",
    "    y_test = strat_test_set[\"median_house_value\"].copy()\n",
    "\n",
    "    X_test_num = X_test.drop('ocean_proximity', axis=1)\n",
    "    X_test_prepared = imputer.transform(X_test_num)\n",
    "    X_test_prepared = pd.DataFrame(\n",
    "        X_test_prepared,\n",
    "        columns=X_test_num.columns, index=X_test.index)\n",
    "    X_test_prepared[\"rooms_per_household\"] = X_test_prepared[\"total_rooms\"]\\\n",
    "        / X_test_prepared[\"households\"]\n",
    "    X_test_prepared[\"bedrooms_per_room\"] = X_test_prepared[\"total_bedrooms\"]\\\n",
    "        / X_test_prepared[\"total_rooms\"]\n",
    "    X_test_prepared[\"population_per_household\"] = \\\n",
    "        X_test_prepared[\"population\"] / X_test_prepared[\"households\"]\n",
    "\n",
    "    X_test_cat = X_test[['ocean_proximity']]\n",
    "    X_test_prepared = X_test_prepared.join(\n",
    "        pd.get_dummies(X_test_cat, drop_first=True))\n",
    "\n",
    "    final_predictions = final_model.predict(X_test_prepared)\n",
    "    final_mse = mean_squared_error(y_test, final_predictions)\n",
    "    final_rmse = np.sqrt(final_mse)\n",
    "    print(\"MSE: \", final_mse)\n",
    "    print(\"RMSE: \", final_rmse)\n",
    "    \n",
    "    global best_parms\n",
    "\n",
    "    return y_test, final_predictions, best_parms, final_model\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    base_path='/root/housing-price-prediction/'\n",
    "    #base_path = pathlib.Path(__file__).parent.parent.resolve()\n",
    "    sys.path.append(os.path.join(base_path,'data/processed'))  # noqa\n",
    "    import ingest_data  # noqa\n",
    "\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--input_data\",\n",
    "                        help=\"Input Path of the data\", default='')\n",
    "    parser.add_argument(\"--model_output_path\",\n",
    "                        help=\"Model save path\", default='')\n",
    "    parser.add_argument(\"--log-level\",\n",
    "                        help=\"Choose Log Level from the choice.\",\n",
    "                        default='DEBUG',\n",
    "                        choices=['DEBUG', 'INFO', 'WARNING', 'ERROR',\n",
    "                                 'CRITICAL'])\n",
    "    parser.add_argument(\"--log-path\",\n",
    "                        help=\"Choose path for log storing\", default='')\n",
    "    parser.add_argument(\"--no-console-log\",\n",
    "                        help=\"Write Logs to console\", default='False')\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    model_output_path = args.model_output_path\n",
    "    input_data = args.input_data\n",
    "    logLevel = args.log_level\n",
    "    log_path = args.log_path\n",
    "    no_console_log = args.no_console_log\n",
    "\n",
    "    logger = logging.getLogger()\n",
    "\n",
    "    if logLevel.upper() == 'CRITICAL':\n",
    "        logging.basicConfig(level=logging.CRITICAL)\n",
    "    if logLevel.upper() == 'ERROR':\n",
    "        logging.basicConfig(level=logging.ERROR)\n",
    "    if logLevel.upper() == 'INFO':\n",
    "        logging.basicConfig(level=logging.INFO)\n",
    "    if logLevel.upper() == 'DEBUG':\n",
    "        logging.basicConfig(level=logging.DEBUG)\n",
    "\n",
    "    if log_path != '':\n",
    "        l1 = os.path.join(log_path, 'Logs.log')\n",
    "        logging.basicConfig(filename=l1)\n",
    "\n",
    "    if no_console_log:\n",
    "        logging.disable(logging.DEBUG)\n",
    "\n",
    "    if input_data == '':\n",
    "        # checks for arguments, if empty calls the data-generation script.\n",
    "        housing = ingest_data.load_housing_data()\n",
    "    else:\n",
    "        housing = pd.read_csv(input_data)\n",
    "\n",
    "    if input_data == '':\n",
    "        # checks for arguments, if empty calls the data-generation script.\n",
    "        housing = ingest_data.load_housing_data()\n",
    "    else:\n",
    "        housing = pd.read_csv(input_data)\n",
    "    \n",
    "\n",
    "    fit_direct_data(housing, model_output_path, base_path=base_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b38ef89b-5c5c-46b8-a943-905901028f7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/root/housing-price-prediction/scripts2'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cde2b7b0-fbbc-405f-9bec-7f4bb96196e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path='/root/housing-price-prediction/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f5ca5e-8ae5-48f8-8700-b03fc4bbcce1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
